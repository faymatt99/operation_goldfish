{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c9c375-b9a7-45ed-bf0c-9f16c4a27c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats\n",
    "import itertools\n",
    "from sklearn import linear_model\n",
    "from numpy import ones,vstack\n",
    "from numpy.linalg import lstsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c41151e-86ee-455f-85fb-cf6499bc418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Ames_Housing_Price_Data_raw.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b410ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index bc data has rows with same indices, i.e. indices start over at 1 at certain points\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb069f",
   "metadata": {},
   "source": [
    "# Type dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20a481d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "typedict = {'PID' : 'nominal',\n",
    "            'SalePrice' : 'continuous',\n",
    "            #Matt\n",
    "            'LotFrontage' : 'continuous', \n",
    "            'LotArea' : 'continuous',\n",
    "            'maybe_LotShape' : 'nominal',\n",
    "            'LandSlope' : 'nominal', \n",
    "            'LandContour' : 'nominal', \n",
    "            'maybe_MSZoning' : 'nominal', \n",
    "            'Street_paved' : 'nominal', \n",
    "            'Alley' : 'nominal',\n",
    "            'Neighborhood' : 'nominal', \n",
    "            'drop_LotConfig' : 'nominal', \n",
    "            'drop_Condition1' : 'nominal', \n",
    "            'drop_Condition2' : 'nominal',\n",
    "            'Foundation' : 'nominal',\n",
    "            'Utilities' : 'nominal',\n",
    "            'Heating' : 'nominal',\n",
    "            'HeatingQC_nom' : 'ordinal',\n",
    "            'CentralAir' : 'nominal',\n",
    "            'Electrical' : 'nominal',\n",
    "            'HeatingQC_ord' : 'ordinal',\n",
    "            'LotShape_com' : 'nominal',\n",
    "            'MSZoning_com' : 'nominal',\n",
    "            'LF_Normal' : 'nominal',\n",
    "            'LF_Near_NS_RR' : 'nominal',\n",
    "            'LF_Near_Positive_Feature' : 'nominal',\n",
    "            'LF_Adjacent_Arterial_St' : 'nominal',\n",
    "            'LF_Near_EW_RR' : 'nominal',\n",
    "            'LF_Adjacent_Feeder_St' : 'nominal',\n",
    "            'LF_Near_Postive_Feature' : 'nominal',\n",
    "            'Heating_com' : 'nominal',\n",
    "            'Electrical_com' : 'nominal',\n",
    "            'LotConfig_com' : 'nominal', \n",
    "            'LotFrontage_log' : 'continuous',\n",
    "            'LotArea_log' : 'continuous',\n",
    "            #Oren \n",
    "            'MiscFeature': 'Nominal',\n",
    "            'Fireplaces': 'Discrete',\n",
    "            'FireplaceQu': 'Ordinal',\n",
    "            'PoolQC': 'Ordinal',\n",
    "            'PoolArea': 'Continuous',\n",
    "            'PavedDrive': 'Nominal',\n",
    "            'ExterQual': 'Ordinal',\n",
    "            'OverallQual': 'Ordinal',\n",
    "            'drop_OverallCond': 'Ordinal',\n",
    "            'MiscVal': 'Continuous',\n",
    "            'YearBuilt': 'Discrete',\n",
    "            'YearRemodAdd': 'Discrete',\n",
    "            'KitchenQual': 'Ordinal',\n",
    "            'Fence': 'Ordinal',\n",
    "            'RoofStyle': 'Nominal',\n",
    "            'RoofMatl': 'Nominal',\n",
    "            'maybe_Exterior1st': 'Nominal',\n",
    "            'drop_Exterior2nd': 'Nominal',\n",
    "            'drop_ExterCond': 'Ordinal',\n",
    "            'maybe_MasVnrType': 'Nominal',\n",
    "            'MasVnrArea': 'Continuous',\n",
    "            #Mo\n",
    "            #Basement\n",
    "            'BsmtQual_ord': 'Ordinal',\n",
    "            'BsmtCond_ord': 'Ordinal',\n",
    "            'BsmtExposure_ord': 'Ordinal',\n",
    "            'BsmtQual_ord_lin': 'Ordinal',\n",
    "            'BsmtCond_ord_lin': 'Ordinal',\n",
    "            'BsmtExposure_ord_lin': 'Ordinal',\n",
    "            'TotalBsmtSF': 'Continuous',\n",
    "            'BSMT_GLQ':'Continuous', \n",
    "            'BSMT_Rec':'Continuous',\n",
    "            'maybe_BsmtUnfSF': 'Continuous',\n",
    "            'maybe_BSMT_ALQ':'Continuous',\n",
    "            'maybe_BSMT_BLQ':'Continuous', \n",
    "            'maybe_BSMT_LwQ':'Continuous', \n",
    "            'drop_BsmtQual': 'Nominal',\n",
    "            'drop_BsmtCond': 'Nominal',\n",
    "            'drop_BsmtExposure': 'Nominal',\n",
    "            'drop_BsmtFinType1': 'Nominal',\n",
    "            'drop_BsmtFinSF1': 'Continuous',\n",
    "            'drop_BsmtFinType2': 'Nominal',\n",
    "            'drop_BsmtFinSF2': 'Continuous',\n",
    "            #Deck\n",
    "            'WoodDeckSF':'Continuous', \n",
    "            'OpenPorchSF':'Continuous', \n",
    "            'ScreenPorch':'Continuous',\n",
    "            'maybe_EnclosedPorch':'Continuous',\n",
    "            'maybe_3SsnPorch':'Continuous',\n",
    "            #Garage\n",
    "            'GarageFinish':'Nominal', \n",
    "            'GarageYrBlt':'Continuous',\n",
    "            'GarageCars':'Ordinal',\n",
    "            'GarageArea':'Continuous',\n",
    "            'GarageType_con':'Nominal',\n",
    "            'maybe_GarageQual':'Nominal', \n",
    "            'maybe_GarageCond':'Nominal',\n",
    "            'drop_GarageType':'Nominal'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30947dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorization of original variables\n",
    "general=['PID','SalePrice']\n",
    "lot_aspects=['LotFrontage','LotArea','LotShape','LandSlope','LandContour']\n",
    "building_size=['MSSubClass','BldgType','HouseStyle','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd']\n",
    "location=['MSZoning','Street','Alley','Neighborhood']\n",
    "location_aspects=['LotConfig','Condition1','Condition2']\n",
    "amenities=['MiscFeature','Fireplaces','FireplaceQu','PoolQC','PoolArea','PavedDrive']\n",
    "garage=['GarageFinish','GarageType','GarageYrBlt','GarageCars','GarageArea','GarageQual','GarageCond']\n",
    "decks=['WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch']\n",
    "basement=['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinSF1','BsmtFinType2','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF']\n",
    "utilities=['Foundation','Utilities','Heating','HeatingQC','CentralAir','Electrical']\n",
    "quality_ratings=['ExterQual','OverallQual','OverallCond','MiscVal','YearBuilt','YearRemodAdd','KitchenQual','Fence','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','ExterCond','MasVnrType','MasVnrArea']\n",
    "sales_aspect=['Functional','SaleCondition','SaleType','MoSold','YrSold']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c82a57",
   "metadata": {},
   "source": [
    "# Matt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f44c49be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add log Price column\n",
    "\n",
    "df['SalePrice_log']=np.log10(df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c4f4b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinalize heating quality ratings\n",
    "HousingQC_dict={\n",
    "       'Ex':5,\n",
    "       'Gd':4,\n",
    "       'TA':3,\n",
    "       'Fa':2,\n",
    "       'Po':1,\n",
    "}\n",
    "\n",
    "df.loc[df['HeatingQC'].isna(),'HeatingQC']='0'\n",
    "df['HeatingQC_ord']=df['HeatingQC'].map(lambda x: HousingQC_dict[x])\n",
    "df.rename(columns={'HeatingQC':'HeatingQC_nom'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4a63eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LotShape: combine IR2 (moderately irregular) and IR3 (irregular) into 'Irregular' due to small sample sizes\n",
    "lot_shape_dict = {\n",
    "    'Reg':'Regular',\n",
    "    'IR1':'Slightly irregular',\n",
    "    'IR2':'Irregular',\n",
    "    'IR3': 'Irregular'\n",
    "}\n",
    "df['LotShape_com'] = df['LotShape'].map(lambda x: lot_shape_dict[x] if x in lot_shape_dict else x)\n",
    "df.rename(columns={'LotShape':'maybe_LotShape'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fbb2082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LandSlope: combine Mod (moderate) and Sev (severe) into 'Moderate-severe' due to small sample sizes\n",
    "land_slope_dict = {\n",
    "    'Gtl':'Gentle',\n",
    "    'Mod':'Moderate-severe',\n",
    "    'Sev':'Moderate-severe'\n",
    "}\n",
    "df['LandSlope'] = df['LandSlope'].map(lambda x: land_slope_dict[x] if x in land_slope_dict else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99dd383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename missing values in Alley column to 'No alley access'\n",
    "alley_dict = {\n",
    "    'Pave':'Paved',\n",
    "    'Grvl':'Gravel',\n",
    "    'No alley access' : 'No alley access'\n",
    "}\n",
    "df.loc[df['Alley'].isna(),'Alley'] = 'No alley access'\n",
    "df['Alley'] = df['Alley'].map(lambda x: alley_dict[x] if x in alley_dict else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28e7f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple renaming LandContour values for clarity\n",
    "LandContour_dict = {\n",
    "    'Lvl':'Level',\n",
    "    'Bnk':'Banked (rise from street level to building)',\n",
    "    'HLS' : 'Hillside (downward slope on both sides)',\n",
    "    'Low' : 'Depression (upward slope on both sides)'\n",
    "}\n",
    "\n",
    "df['LandContour'] = df['LandContour'].map(lambda x: LandContour_dict[x] if x in LandContour_dict else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b3ab91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine C(all) (commercial), I(all) (industrial), and A(agr) (agricultural) zoning types into 'Nonresidential' due to\n",
    "# small sample sizes and the fact that we are focusing on residential sales\n",
    "MSZoning_dict = {\n",
    "    'RL':'Residential, low-density',\n",
    "    'RM':'Residential, medium-density',\n",
    "    'FV' : 'Residential, village',\n",
    "    'RH' : 'Residential, high-density',\n",
    "    'C (all)' : 'Nonresidential',\n",
    "    'I (all)' : 'Nonresidential',\n",
    "    'A (agr)' : 'Nonresidential'\n",
    "}\n",
    "\n",
    "df['MSZoning_com'] = df['MSZoning'].map(lambda x: MSZoning_dict[x] if x in MSZoning_dict else x)\n",
    "df.rename(columns={'MSZoning':'maybe_MSZoning'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce801e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine 'Near (within 200 ft)' and 'Adjacent to' into 'Near' for North-South RR, East-West RR, and positive features (parks, greenways, etc)\n",
    "# renaming them LF_<factor> for Location Factor instead of condition to avoid confusion, as condition is also used to describe\n",
    "# state of maintenance of various other features in the dataset\n",
    "Condition_dict = {\n",
    "    'Norm' : 'LF_Normal',\n",
    "    'RRAn' : 'LF_Near_NS_RR',\n",
    "    'PosN' : 'LF_Near_Positive_Feature',\n",
    "    'Artery' : 'LF_Adjacent_Arterial_St',\n",
    "    'RRAe' : 'LF_Near_EW_RR',\n",
    "    'Feedr' : 'LF_Adjacent_Feeder_St',\n",
    "    'PosA' : 'LF_Near_Postive_Feature',\n",
    "    'RRNn' : 'LF_Near_NS_RR',\n",
    "    'RRNe' : 'LF_Near_EW_RR'\n",
    "}\n",
    "\n",
    "df['Condition1'] = df['Condition1'].map(lambda x: Condition_dict[x] if x in Condition_dict else x)\n",
    "df['Condition2'] = df['Condition2'].map(lambda x: Condition_dict[x] if x in Condition_dict else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1afd1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_condition_columns(df, factors):\n",
    "    '''\n",
    "    combines the \"Condition1_com\" and \"Condition2_com\" columns into a set of dummies for the values in those 2 columns\n",
    "    '''\n",
    "    for i in range(0, df.shape[0]):\n",
    "        for factor in factors:\n",
    "            if df.loc[i, 'Condition1'] == factor or df.loc[i, 'Condition2'] == factor:\n",
    "                df.loc[i, f'{factor}'] = '1'\n",
    "            else:\n",
    "                df.loc[i, f'{factor}'] = '0'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4451209",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_factors = Condition_dict.values()\n",
    "df = combine_condition_columns(df, loc_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0aca1831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend drop condition columns\n",
    "df.rename(columns={'Condition1':'drop_Condition1'}, inplace=True)\n",
    "df.rename(columns={'Condition2':'drop_Condition2'}, inplace=True)\n",
    "df.rename(columns={'LF_Normal':'drop_LF_Normal'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbf5b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Street':'Street_paved'}, inplace=True) # renaming 'Street' to 'Street_paved'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4cad4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities: simple renaming for clarity\n",
    "Utilities_dict = {\n",
    "    'AllPub':'EGWS',\n",
    "    'NoSewr':'EGW with septic tank'\n",
    "}\n",
    "\n",
    "df['Utilities'] = df['Utilities'].map(lambda x: Utilities_dict[x] if x in Utilities_dict else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "409ffe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine 'Gravity furnace', 'Other water/steam heating', 'Floor furnace', and 'Wall furnace' into 'Other' due to\n",
    "# small sample size\n",
    "Heating_dict = {\n",
    "    'GasA':'Gas-powered forced-air heating',\n",
    "    'GasW':'Gas-powered water/steam heating',\n",
    "    'Grav' : 'Other',\n",
    "    'OthW' : 'Other',\n",
    "    'Floor' : 'Other',\n",
    "    'Wall' : 'Other'\n",
    "}\n",
    "\n",
    "df['Heating_com'] = df['Heating'].map(lambda x: Heating_dict[x] if x in Heating_dict else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "765ececf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming for clarity and combining FuseP and FuseF categories due to small sample size\n",
    "# they are also the 2 most undesirable electrical setups as reported by the data dictionary\n",
    "Electrical_dict = {\n",
    "    'SBrkr': 'Standard circuit breakers, all Romex wiring',\n",
    "    'FuseA': '>60 Amp fuse box, all Romex wiring',\n",
    "    'FuseF' : '60 Amp fuse box, Romex or older wiring',\n",
    "    'FuseP' : '60 Amp fuse box, Romex or older wiring'\n",
    "}\n",
    "\n",
    "df['Electrical_com'] = df['Electrical'].map(lambda x: Electrical_dict[x] if x in Electrical_dict else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02094601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined FR2 (2 sides frontage) and FR3 (3 sides frontage) into 2+ sides frontage due to small sample size\n",
    "LotConfig_dict = {\n",
    "    'Inside': 'Inside lot (1 side frontage)',\n",
    "    'Corner': 'Corner lot',\n",
    "    'CulDSac' : 'Cul-de-sac lot',\n",
    "    'FR2' : '2+ sides frontage',\n",
    "    'FR3' : '2+ sides frontage'\n",
    "}\n",
    "\n",
    "df['LotConfig_com'] = df['LotConfig'].map(lambda x: LotConfig_dict[x] if x in LotConfig_dict else x)\n",
    "df.rename(columns={'LotConfig':'drop_LotConfig'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e87fdfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotFrontage_log'] = np.log(df['LotFrontage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c95db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotArea_log'] = np.log(df['LotArea'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e61826",
   "metadata": {},
   "source": [
    "# Oren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00c6cb2c-0c9f-4b32-94bb-723e7e684784",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cond_dict={\n",
    "       'Ex':5,\n",
    "       'Gd':4,\n",
    "       'TA':3,\n",
    "       'Fa':2,\n",
    "       'Po':1,\n",
    "       'NA':0,\n",
    "        '0':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a86353fd-4ca8-4288-8bee-b4b5197230f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['ExterQual'].isna(),'ExterQual']='0'\n",
    "df['ExterQual']=df['ExterQual'].map(lambda x: Cond_dict[x])\n",
    "\n",
    "df.loc[df['ExterCond'].isna(),'ExterCond']='0'\n",
    "df['ExterCond']=df['ExterCond'].map(lambda x: Cond_dict[x])\n",
    "\n",
    "df.loc[df['KitchenQual'].isna(),'KitchenQual']='0'\n",
    "df['KitchenQual']=df['KitchenQual'].map(lambda x: Cond_dict[x])\n",
    "\n",
    "df.loc[df['FireplaceQu'].isna(),'FireplaceQu']='0'\n",
    "df['FireplaceQu']=df['FireplaceQu'].map(lambda x: Cond_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e756e248-d756-4605-bc24-54ae150c0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Paved_Drive_Dict={\n",
    "       'Y':'Paved' ,\n",
    "       'P':'Partial Pavement',\n",
    "       'N':'Dirt Gravel'\n",
    "}\n",
    "df['PavedDrive']=df['PavedDrive'].map(lambda x: Paved_Drive_Dict[x] if x != 'NA' else x)\n",
    "\n",
    "Fence_Dict={\n",
    "       'GdPrv':'Good Privacy',\n",
    "       'MnPrv':'Minimum Privacy',\n",
    "       'GdWo':'Good Wood',\n",
    "       'MnWw':'Minimum Wood/Wire',\n",
    "       'NA':'No Fence'\n",
    "}\n",
    "df.loc[df['Fence'].isna(),'Fence'] = 'NA'\n",
    "df['Fence']=df['Fence'].map(lambda x: Fence_Dict[x])\n",
    "\n",
    "Misc_Feature_Dict={\n",
    "       'Elev':'Elevator',\n",
    "       'Gar2':'2nd Garage',\n",
    "       'Othr':'Other',\n",
    "       'Shed':'Shed',\n",
    "       'TenC':'Tennis Court',\n",
    "       'NA':'Nothing'\n",
    "}\n",
    "df.loc[df['MiscFeature'].isna(),'MiscFeature'] = 'NA'\n",
    "df['MiscFeature']=df['MiscFeature'].map(lambda x: Misc_Feature_Dict[x])\n",
    "\n",
    "\n",
    "Roof_Style_Dict={\n",
    "       'Flat':'Flat',\n",
    "       'Gable':'Gable',\n",
    "       'Gambrel':'Gabrel Barn',\n",
    "       'Hip':'Hip',\n",
    "       'Mansard':'Mansard',\n",
    "       'Shed':'Shed'\n",
    "}\n",
    "df['RoofStyle']=df['RoofStyle'].map(lambda x: Roof_Style_Dict[x] if x != 'NA' else x)  \n",
    "    \n",
    "    \n",
    "Roof_Matl_Dict={\n",
    "       'ClyTile':'Clay or Tile',\n",
    "       'CompShg':'Standard (Composite) Shingle',\n",
    "       'Membran':'Membrane',\n",
    "       'Metal':'Metal',\n",
    "       'Roll':'Roll',\n",
    "       'Tar&Grv':'Gravel & Tar',\n",
    "       'WdShake':'Wood Shakes',\n",
    "       'WdShngl':'Wood Shingles'\n",
    "}\n",
    "df['RoofMatl']=df['RoofMatl'].map(lambda x: Roof_Matl_Dict[x] if x != 'NA' else x)    \n",
    "    \n",
    "Exterior_Dict={\n",
    "       'AsbShng':'Asbestos Shingles',\n",
    "       'AsphShn':'Asphalt Shingles',\n",
    "       'BrkComm':'Brick Common',\n",
    "       'BrkFace':'Brick Face',\n",
    "       'CBlock':'Cinder Block',\n",
    "       'CemntBd':'Cement Board',\n",
    "       'CmentBd':'Cement Board',\n",
    "       'HdBoard':'Hard Board',\n",
    "       'ImStucc':'Imitation Stucco',\n",
    "       'MetalSd':'Metal Siding',\n",
    "       'Other':'Other',\n",
    "       'Plywood':'Plywood',\n",
    "       'PreCast':'PreCast',\n",
    "       'Stone':'Stone',\n",
    "       'Stucco':'Stucco',\n",
    "       'VinylSd':'Vinyl Siding',\n",
    "       'Wd Sdng':'Wood Siding',\n",
    "       'WdShing':'Wood Shingles',\n",
    "       'Wd Shng':'Wood Shingles',\n",
    "        'Brk Cmn':'Brick Common'\n",
    "}\n",
    "df['Exterior1st']=df['Exterior1st'].map(lambda x: Exterior_Dict[x] if x != 'NA' else x)\n",
    "df['Exterior2nd']=df['Exterior2nd'].map(lambda x: Exterior_Dict[x] if x != 'NA' else x)\n",
    "\n",
    "Mas_Vnr_Type_Dict={\n",
    "       'BrkCmn':'Brick Common',\n",
    "       'BrkFace':'Brick Face',\n",
    "       'CBlock':'Cinder Block',\n",
    "       'None':'None',\n",
    "       'Stone':'Stone'\n",
    "}\n",
    "df.loc[df['MasVnrType'].isna(),'MasVnrType'] = 'None'\n",
    "df['MasVnrType']=df['MasVnrType'].map(lambda x: Mas_Vnr_Type_Dict[x] if x != 'NA' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9c30a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_exterior_columns(df, factors):\n",
    "    '''\n",
    "    combines the \"Condition1_com\" and \"Condition2_com\" columns into a set of dummies for the values in those 2 columns\n",
    "    '''\n",
    "    for i in range(0, df.shape[0]):\n",
    "        for factor in factors:\n",
    "            if df.loc[i, 'Exterior1st'] == factor or df.loc[i, 'Exterior2nd'] == factor:\n",
    "                df.loc[i, f'{factor}'] = '1'\n",
    "            else:\n",
    "                df.loc[i, f'{factor}'] = '0'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bbff564",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=combine_exterior_columns(df, ['Exterior1st', 'Exterior2nd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b863ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    # Columns to drop/maybe\n",
    "    'OverallCond': 'maybe_OverallCond',\n",
    "    'ExterCond': 'maybe_ExterCond',\n",
    "    'Exterior2nd':'drop_Exterior2nd',\n",
    "    'MasVnrType': 'maybe_MasVnrType',  \n",
    "    'Exterior1st': 'drop_Exterior1st',\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae51325a",
   "metadata": {},
   "source": [
    "# Mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4a10a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_selection(x):\n",
    "    '''\n",
    "    Iterate throuh all combunaions of variables and linearly regress to find optimal variables to utilize/ drop\n",
    "    '''\n",
    "\n",
    "    lm=linear_model.LinearRegression()\n",
    "\n",
    "    for i in range(1,len(x.columns)):\n",
    "        scores = {}\n",
    "\n",
    "        for item in set(itertools.combinations(x.columns, i)):\n",
    "            lm.fit(x[list(item)], df['SalePrice'])\n",
    "            scores[item]=lm.score(x[list(item)], df['SalePrice'])\n",
    "\n",
    "        print(scores[max(scores, key=lambda key: scores[key])])\n",
    "        print(max(scores, key=lambda key: scores[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50c1edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace nominal with ordinal variables on standard scale with even steps\n",
    "\n",
    "def linarization_func(var_name):\n",
    "    '''\n",
    "    Input: ordinal variable name as string\n",
    "    Function creates new variable with naming *_lin that linarizes the ordinal scale \n",
    "    based on relationship to mean sales\n",
    "    Variable needs to be part of a dataframe named df, which also includes oclumn 'SalePrice'\n",
    "    '''\n",
    "\n",
    "    #linear function between min and max of mean\n",
    "    meanlist=df[['SalePrice',f'{var_name}']].groupby(f'{var_name}').agg('mean')\n",
    "\n",
    "    points = [(0,min(meanlist['SalePrice'])),(1,max(meanlist['SalePrice']))]\n",
    "    x_coords, y_coords = zip(*points)\n",
    "    A = vstack([x_coords,ones(len(x_coords))]).T\n",
    "    m, c = lstsq(A, y_coords, rcond=None)[0]\n",
    "\n",
    "    #loop reassigning x: current mean, future mean(x_pos on lin function)\n",
    "    dict={}\n",
    "\n",
    "    dict[min(df[f'{var_name}'].unique())]=0\n",
    "    dict[max(df[f'{var_name}'].unique())]=1\n",
    "\n",
    "    for i in df[f'{var_name}'].unique():\n",
    "        if not i in dict:\n",
    "            dict[i]=(meanlist.loc[meanlist.index==i,'SalePrice'][i]-c)/m\n",
    "\n",
    "    #new value mapping dictionary\n",
    "    df[f'{var_name}_lin']=df[f'{var_name}'].map(lambda x: dict[x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbc00d7",
   "metadata": {},
   "source": [
    "Basement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3680bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dict={\n",
    "       'Ex':5,\n",
    "       'Gd':4,\n",
    "       'TA':3,\n",
    "       'Fa':2,\n",
    "       'Po':1,\n",
    "       'NA':0,\n",
    "        '0':0\n",
    "}\n",
    "\n",
    "exp_dict={\n",
    "       'Gd':4,\n",
    "       'Av':3,\n",
    "       'Mn':2,\n",
    "       'No':1,\n",
    "       'NA':0,\n",
    "        '0':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2aab581",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace nominal with ordinal variables on standard scale with even steps\n",
    "df['BsmtCond_ord']=df['BsmtCond']\n",
    "df.rename(columns = {'BsmtCond': 'drop_BsmtCond'}, inplace=True)\n",
    "df.loc[df['BsmtCond_ord'].isna(),'BsmtCond_ord']='0'\n",
    "df['BsmtCond_ord']=df['BsmtCond_ord'].map(lambda x: master_dict[x])\n",
    "\n",
    "df['BsmtQual_ord']=df['BsmtQual']\n",
    "df.rename(columns = {'BsmtQual': 'drop_BsmtQual'}, inplace=True)\n",
    "df.loc[df['BsmtQual_ord'].isna(),'BsmtQual_ord']='0'\n",
    "df['BsmtQual_ord']=df['BsmtQual_ord'].map(lambda x: master_dict[x])\n",
    "\n",
    "df['BsmtExposure_ord']=df['BsmtExposure']\n",
    "df.rename(columns = {'BsmtExposure': 'drop_BsmtExposure'}, inplace=True)\n",
    "df.loc[df['BsmtExposure_ord'].isna(),'BsmtExposure_ord']='0'\n",
    "df['BsmtExposure_ord']=df['BsmtExposure_ord'].map(lambda x: exp_dict[x])\n",
    "\n",
    "#drop 'unf' and 'NaN' dummies from BsmtFinType1 and BsmtFinType2 (unf covered through separate dumym already)\n",
    "#need to merge dummies for BsmtFinType1 and BsmtFinType2\n",
    "df['BSMT_GLQ']=0\n",
    "df['BSMT_ALQ']=0\n",
    "df['BSMT_BLQ']=0\n",
    "df['BSMT_LwQ']=0\n",
    "df['BSMT_Rec']=0\n",
    "\n",
    "df.loc[df['BsmtFinType1'] == 'GLQ','BSMT_GLQ']=df.loc[df['BsmtFinType1'] == 'GLQ','BsmtFinSF1']\n",
    "df.loc[df['BsmtFinType2'] == 'GLQ','BSMT_GLQ']=df.loc[df['BsmtFinType2'] == 'GLQ','BsmtFinSF2']\n",
    "\n",
    "df.loc[df['BsmtFinType1'] == 'ALQ','BSMT_ALQ']=df.loc[df['BsmtFinType1'] == 'ALQ','BsmtFinSF1']\n",
    "df.loc[df['BsmtFinType2'] == 'ALQ','BSMT_ALQ']=df.loc[df['BsmtFinType2'] == 'ALQ','BsmtFinSF2']\n",
    "\n",
    "df.loc[df['BsmtFinType1'] == 'BLQ','BSMT_BLQ']=df.loc[df['BsmtFinType1'] == 'BLQ','BsmtFinSF1']\n",
    "df.loc[df['BsmtFinType2'] == 'BLQ','BSMT_BLQ']=df.loc[df['BsmtFinType2'] == 'BLQ','BsmtFinSF2']\n",
    "\n",
    "df.loc[df['BsmtFinType1'] == 'LwQ','BSMT_LwQ']=df.loc[df['BsmtFinType1'] == 'LwQ','BsmtFinSF1']\n",
    "df.loc[df['BsmtFinType2'] == 'LwQ','BSMT_LwQ']=df.loc[df['BsmtFinType2'] == 'LwQ','BsmtFinSF2']\n",
    "\n",
    "df.loc[df['BsmtFinType1'] == 'Rec','BSMT_Rec']=df.loc[df['BsmtFinType1'] == 'Rec','BsmtFinSF1']\n",
    "df.loc[df['BsmtFinType2'] == 'Rec','BSMT_Rec']=df.loc[df['BsmtFinType2'] == 'Rec','BsmtFinSF2']\n",
    "\n",
    "df.rename(columns = {'BsmtFinType1': 'drop_BsmtFinType1','BsmtFinSF1': 'drop_BsmtFinSF1','BsmtFinType2': 'drop_BsmtFinType2','BsmtFinSF2': 'drop_BsmtFinSF2'}, inplace=True)\n",
    "\n",
    "df.loc[df['TotalBsmtSF'].isna(),'TotalBsmtSF']=0\n",
    "df.loc[df['BsmtUnfSF'].isna(),'BsmtUnfSF']=0\n",
    "\n",
    "#further columns I recommend we drop, based on them not having any effect by themselves on predicting sales prices\n",
    "df.rename(columns = {'BsmtUnfSF': 'maybe_BsmtUnfSF','BSMT_ALQ': 'maybe_BSMT_ALQ','BSMT_BLQ': 'maybe_BSMT_BLQ','BSMT_LwQ': 'maybe_BSMT_LwQ','BsmtExposure': 'maybe_BsmtExposure'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ffcaea",
   "metadata": {},
   "source": [
    "Porches/ Decks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1d47f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'EnclosedPorch': 'maybe_EnclosedPorch','3SsnPorch': 'maybe_3SsnPorch'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a7edea",
   "metadata": {},
   "source": [
    "Garage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "416c3ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#consolidate Garage Types based on better predicitve power and low impact of other types\n",
    "garagetype={\n",
    "   'Detchd':'Detchd', \n",
    "    'Attchd':'Attchd', \n",
    "    'BuiltIn':'BuiltIn', \n",
    "    'Basment':'Detchd',  \n",
    "    '2Types':'Detchd', \n",
    "    'CarPort':'Detchd',\n",
    "    '0':'0'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c5ebffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageType_con']=df['GarageType']\n",
    "df.rename(columns = {'GarageType': 'drop_GarageType'}, inplace=True)\n",
    "df.loc[df['GarageType_con'].isna(),'GarageType_con']='0'\n",
    "df['GarageType_con']=df['GarageType_con'].map(lambda x: garagetype[x])\n",
    "\n",
    "#drop GarageCond, GarageQual (basically no value, also almost all values are consolidated in one status)\n",
    "df.rename(columns = {'GarageCond': 'maybe_GarageCond','GarageQual': 'maybe_GarageQual'}, inplace=True)\n",
    "\n",
    "#keep year, area, Finish, cars as is, all have strong predictive power and do not seem to allow for easy consolidation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49845c17",
   "metadata": {},
   "source": [
    "## Hao-Wei\n",
    "\n",
    "There is an all-in-one pack function called `data_cleaning_part_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02b930f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MB_dict = {\n",
    "    20: \"1-Story\",\n",
    "    30: \"1-Story\",\n",
    "    40: \"1-Story\",\n",
    "    120: \"1-Story\",\n",
    "    45: \"1.5-Story\",\n",
    "    50: \"1.5-Story\",\n",
    "    150: \"1.5-Story\",\n",
    "    60: \"2-Story\",\n",
    "    70: \"2-Story\",\n",
    "    160: \"2-Story\",\n",
    "    75: \"2.5-Story\",\n",
    "    80: \"SplitMulti\",\n",
    "    180: \"SplitMulti\",\n",
    "    190: \"2FamConv\",\n",
    "    85: \"SptFoyer\",\n",
    "    90: \"Duplex\"\n",
    "};\n",
    "df[\"MS_coded\"] = df[\"MSSubClass\"].apply(lambda x: MB_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbd95326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_floors(feat1, feat2):\n",
    "    floors = []\n",
    "    zipped = zip(feat1, feat2)\n",
    "    for item in zipped: \n",
    "        if item[0] in ['1-Story', '1.5-Story', '2-Story', '2.5-Story']:\n",
    "            ms_coded_dict = {\n",
    "                '1-Story' : 1,\n",
    "                '1.5-Story' : 1,\n",
    "                '2-Story' : 2,\n",
    "                '2.5-Story' : 2\n",
    "            }\n",
    "            floors.append(ms_coded_dict[item[0]])\n",
    "        else:\n",
    "            HouseStyle_dict = {\n",
    "                '1Story' : 1,\n",
    "                '1.5Fin' : 1,\n",
    "                '1.5Unf' : 1,\n",
    "                '2Story' : 2,\n",
    "                '2.5Fin' : 2,\n",
    "                '2.5Unf' : 2,\n",
    "                'SLvl' : 2,\n",
    "                'SFoyer' : 2\n",
    "            }\n",
    "            floors.append(HouseStyle_dict[item[1]])\n",
    "    return floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba0446a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['number_floors'] = calc_floors(df['MS_coded'], df['HouseStyle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df1b9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_attic(feat1):\n",
    "    attic = []\n",
    "    for item in feat1: \n",
    "        if not (item in ['1.5Fin', '1.5Unf', '2.5Fin', '2.5Unf']):\n",
    "            attic.append('No attic')\n",
    "        else:\n",
    "            if 'Fin' in item:\n",
    "                attic.append('Finished')\n",
    "            if 'Unf' in item:\n",
    "                attic.append('Unfinished')\n",
    "    return attic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bca7b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['attic'] = calc_attic(df['HouseStyle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e3a5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PUD'] = df['MSSubClass'].apply(lambda x: 1 if x in [120, 150, 160, 180] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c22a7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[653,['BldgType']] = '2fmCon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b56facdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning_part_2(housing):\n",
    "    '''\n",
    "    Input variable:\n",
    "    housing: a compatible dataframe.\n",
    "    \n",
    "    Description:\n",
    "    Assume that housing is the dataframe directly imported from person2.csv,\n",
    "    the function fills up the NA values and add some columns Hao-Wei felt necessary.\n",
    "    For an explanation of the columns, see the dictionary above and the original description file.\n",
    "    '''\n",
    "    df = housing.fillna(0);\n",
    "    # df = df.drop(\"PID\", axis = 1);\n",
    "    df = df.reset_index(drop= True);\n",
    "    \n",
    "    # Ordinal variable handling\n",
    "    functionality_dict={\n",
    "        \"Typ\": 7, # Typical Functionality\n",
    "        \"Min1\": 6, # Minor Deductions 1\n",
    "        \"Min2\": 5, # Minor Deductions 2\n",
    "        \"Mod\": 4, # Moderate Deductions\n",
    "        \"Maj1\": 3, # Major Deductions 1\n",
    "        \"Maj2\": 2, # Major Deductions 2\n",
    "        \"Sev\": 1, # Severely Damaged\n",
    "        \"Sal\": 0, # Salvage only\n",
    "    };\n",
    "    df.loc[df[\"Functional\"].isna(), \"Functional\"]='0';\n",
    "    df[\"Functional_dis\"]=df[\"Functional\"].map(lambda x: functionality_dict[x]);\n",
    "    df = df.rename(columns = {\"Functional\": \"Functional_ord\"}); # 21\n",
    "    \n",
    "    # Adding columns with log scales\n",
    "\n",
    "    temp = pd.DataFrame({\"1stFlrSF_log\": np.log10(df[\"1stFlrSF\"]),\n",
    "                        \"2ndFlrSF_log\": np.log10(df[\"2ndFlrSF\"]+1), # +1 to avoid -inf\n",
    "                        \"GrLivArea_log\": np.log10(df[\"GrLivArea\"])});\n",
    "    df = pd.concat([df, temp], axis = 1); # 24\n",
    "    \n",
    "    # Add weight columns for bathrooms\n",
    "#     half_equiv = [0.3, 0.5];\n",
    "\n",
    "#     temp_dict = {};\n",
    "#     for eq in half_equiv:\n",
    "#         temp_dict[\"BsmtEqBath_\"+\"{:.1f}\".format(eq)] = df[\"BsmtFullBath\"] + eq*df[\"BsmtHalfBath\"];\n",
    "#         temp_dict[\"EqBath_\"+\"{:.1f}\".format(eq)] =  df[\"FullBath\"] + eq*df[\"HalfBath\"];\n",
    "\n",
    "#     temp = pd.DataFrame(temp_dict);\n",
    "#     df = pd.concat([df, temp], axis = 1); # 28\n",
    "\n",
    "    # Extract nominal columns for better interpretation.\n",
    "#     temp_dict = {};\n",
    "#     temp_dict[\"1-Story\"]    = df.apply(lambda x: x[\"MSSubClass\"] in [20, 30, 40, 120], axis=1);\n",
    "#     temp_dict[\"1.5-Story\"]  = df.apply(lambda x: x[\"MSSubClass\"] in [45, 50, 150], axis=1);\n",
    "#     temp_dict[\"2-Story\"]    = df.apply(lambda x: x[\"MSSubClass\"] in [60, 70, 160], axis=1);\n",
    "#     temp_dict[\"2.5-Story\"]  = df.apply(lambda x: x[\"MSSubClass\"] == 75, axis=1);\n",
    "#     temp_dict[\"SplitMulti\"] = df.apply(lambda x: x[\"MSSubClass\"] in [80, 180], axis=1);\n",
    "#     temp_dict[\"2FamConv\"]   = df.apply(lambda x: x[\"MSSubClass\"] == 190, axis=1);\n",
    "#     temp_dict[\"SptFoyer\"]   = df.apply(lambda x: x[\"MSSubClass\"] == 85, axis=1);\n",
    "#     temp_dict[\"Duplex\"]     = df.apply(lambda x: x[\"MSSubClass\"] == 90, axis=1);\n",
    "#     temp_dict[\"Unfinished\"] = df.apply(lambda x: x[\"MSSubClass\"] == 190, axis=1) | df.apply(lambda x: x[\"HouseStyle\"] in [\"1.5Unf\", \"2.5Unf\"], axis=1);\n",
    "#     temp_dict[\"PUD\"]        = df.apply(lambda x: x[\"MSSubClass\"] in [120, 150, 160, 180], axis=1);\n",
    "#     temp_dict[\"1Fam\"]       = df.apply(lambda x: x[\"BldgType\"] == \"1Fam\", axis=1);\n",
    "#     temp_dict[\"TwnhsE\"]     = df.apply(lambda x: x[\"BldgType\"] == \"TwnhsE\", axis=1);\n",
    "#     temp_dict[\"TwnhsI\"]     = df.apply(lambda x: x[\"BldgType\"] == \"TwnhsI\", axis=1);\n",
    "\n",
    "    temp = pd.DataFrame(temp_dict).astype(int);\n",
    "    df = pd.concat([df, temp], axis = 1); # 41, 42 if PID not dropped\n",
    "    \n",
    "    # Some of my personal selection\n",
    "    cols_drop = [\"MSSubClass\", \"HouseStyle\"]; # No more \"BldgType\"\n",
    "    cols_maybe = [\"LowQualFinSF\", \"BsmtHalfBath\", \"HalfBath\", \"MoSold\", \"YrSold\"];\n",
    "    \n",
    "    col_dict = {};\n",
    "    for dr in cols_drop:\n",
    "        col_dict[dr] = \"drop_\" + dr;\n",
    "    for dr in cols_maybe:\n",
    "        col_dict[dr] = \"maybe_\" + dr;\n",
    "    \n",
    "    df.rename(columns=col_dict, inplace=True);\n",
    "    \n",
    "    return df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74da4db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datetime(df):\n",
    "    sold_datetime = []\n",
    "    for i in range(len(df)-1):\n",
    "        curr_sold = datetime(year = (df['YrSold'])[i], month = (df['MoSold'])[i], day = 1)\n",
    "        sold_datetime.append(curr_sold)\n",
    "    return pd.Series(sold_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "995781e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "df['sold_datetime'] = make_datetime(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e6f0255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create linearized variables for these three prdinal variables\n",
    "# linarization_func('BsmtCond_ord')\n",
    "# linarization_func('BsmtQual_ord')\n",
    "# linarization_func('BsmtExposure_ord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b7dc65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in df.columns if c[0:5] != 'drop_']\n",
    "df=df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "285d2057",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/ames_housing_price_data_v2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42dc007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
